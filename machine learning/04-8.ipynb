{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614b82ca-8fad-4799-85d2-7a1cfccf090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22892aa2-9d5e-463e-bdcd-8271c44d055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 10, 10)\n",
    "Y = X + np.random.randn(*X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415b2f70-f3fd-44a8-bea8-5ee55e5b1969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.1)\n",
      "(1.1, 0.7)\n",
      "(2.2, 3.5)\n",
      "(3.3, 2.7)\n",
      "(4.4, 5.7)\n",
      "(5.6, 5.2)\n",
      "(6.7, 6.1)\n",
      "(7.8, 7.4)\n",
      "(8.9, 9.2)\n",
      "(10.0, 9.9)\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(X,Y):\n",
    "    print((round(x,1), round(y,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b3090e-e4f1-443b-bf25-5702f58952de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=1, units=1, activation=\"linear\", use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fae91a-165b-4b8b-9e18-1603f677ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=0.05)\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ecc8c5-cd49-45b0-abfb-959a0b08f61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.0256594]], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82942f52-5408-490a-83e1-09e224e094da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0256594"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = weights[0][0][0]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3853ef48-ba32-4178-9bf6-413607062dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6099\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5799\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5773\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5770\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5770\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5770\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5770\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5770\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5770\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25630f10690>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=10, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cdc24b-7892-458b-ac4b-4b871214da12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, label = 'data')\n",
    "plt.plot(X, w*X, label = 'prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dab6eae-87a0-41bf-ae99-ba4e1a3e1597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0256594"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = weights[0][0][0]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebcc851-ab9b-4f30-8aa3-6d5eea7832c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a19eafb4-fdd6-4f36-b6b2-d436d10452c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(input_dim = 1, units= 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'sgd',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbfd642-1fd5-45af-b761-29303e2eca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([-2, -1.5, -1, 1.25, 1.62, 2])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd36012-57df-415e-9f04-0dd14153a6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.6258 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5499 - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4769 - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4065 - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3388 - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2736 - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2108 - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1503 - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0921 - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0361 - binary_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9822 - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9303 - binary_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8803 - binary_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8323 - binary_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7860 - binary_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7414 - binary_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6985 - binary_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6571 - binary_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6173 - binary_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5790 - binary_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5420 - binary_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5064 - binary_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4720 - binary_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4389 - binary_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4069 - binary_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3761 - binary_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3463 - binary_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3176 - binary_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2898 - binary_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2630 - binary_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2371 - binary_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2120 - binary_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1878 - binary_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1643 - binary_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1416 - binary_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1196 - binary_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0983 - binary_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0776 - binary_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0576 - binary_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0382 - binary_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0193 - binary_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0010 - binary_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9832 - binary_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9660 - binary_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9492 - binary_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9329 - binary_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9170 - binary_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9015 - binary_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8865 - binary_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8719 - binary_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8576 - binary_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8437 - binary_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8301 - binary_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8169 - binary_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8040 - binary_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7914 - binary_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7792 - binary_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7672 - binary_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7554 - binary_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7440 - binary_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7328 - binary_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7219 - binary_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7112 - binary_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7007 - binary_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6905 - binary_accuracy: 0.8333\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6805 - binary_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6707 - binary_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6611 - binary_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6517 - binary_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6424 - binary_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6334 - binary_accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6246 - binary_accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6159 - binary_accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6074 - binary_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5991 - binary_accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5909 - binary_accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5829 - binary_accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5750 - binary_accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5673 - binary_accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5597 - binary_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5523 - binary_accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5450 - binary_accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5378 - binary_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5307 - binary_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5238 - binary_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5170 - binary_accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5104 - binary_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5038 - binary_accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4974 - binary_accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4910 - binary_accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4848 - binary_accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4787 - binary_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4727 - binary_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4668 - binary_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4610 - binary_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4553 - binary_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4496 - binary_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4441 - binary_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4387 - binary_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4333 - binary_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4281 - binary_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4229 - binary_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4178 - binary_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - binary_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4079 - binary_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4031 - binary_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3983 - binary_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3936 - binary_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3890 - binary_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3845 - binary_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3800 - binary_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3756 - binary_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3713 - binary_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3670 - binary_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3628 - binary_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3587 - binary_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3546 - binary_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3506 - binary_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3466 - binary_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3428 - binary_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3389 - binary_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3352 - binary_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3315 - binary_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3278 - binary_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3242 - binary_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3207 - binary_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3172 - binary_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3138 - binary_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3104 - binary_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3071 - binary_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3038 - binary_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3005 - binary_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2974 - binary_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2942 - binary_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2911 - binary_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2881 - binary_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2851 - binary_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2821 - binary_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2792 - binary_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2763 - binary_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2735 - binary_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2707 - binary_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2680 - binary_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2653 - binary_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2626 - binary_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2600 - binary_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2574 - binary_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2548 - binary_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2523 - binary_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2498 - binary_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2474 - binary_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2450 - binary_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2426 - binary_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2402 - binary_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2379 - binary_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2357 - binary_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2334 - binary_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2312 - binary_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2290 - binary_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2268 - binary_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2247 - binary_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2226 - binary_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2206 - binary_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2185 - binary_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2165 - binary_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2145 - binary_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2126 - binary_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2106 - binary_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2087 - binary_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2069 - binary_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2050 - binary_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2032 - binary_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2014 - binary_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1996 - binary_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1978 - binary_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1961 - binary_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1944 - binary_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1927 - binary_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1910 - binary_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1894 - binary_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1878 - binary_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1862 - binary_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1846 - binary_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1830 - binary_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1815 - binary_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1800 - binary_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1785 - binary_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1770 - binary_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1755 - binary_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1741 - binary_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1727 - binary_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1713 - binary_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1699 - binary_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1685 - binary_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1671 - binary_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1658 - binary_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1645 - binary_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1632 - binary_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1619 - binary_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1606 - binary_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1593 - binary_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1581 - binary_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1569 - binary_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1557 - binary_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1545 - binary_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1533 - binary_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1521 - binary_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1510 - binary_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1498 - binary_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1487 - binary_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1476 - binary_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1465 - binary_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1454 - binary_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1443 - binary_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1432 - binary_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1422 - binary_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1412 - binary_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1401 - binary_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1391 - binary_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1381 - binary_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1371 - binary_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1361 - binary_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1352 - binary_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1342 - binary_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1333 - binary_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1323 - binary_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1314 - binary_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1305 - binary_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1296 - binary_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1287 - binary_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1278 - binary_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1269 - binary_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1261 - binary_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1252 - binary_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1244 - binary_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1235 - binary_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1227 - binary_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1219 - binary_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1211 - binary_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1203 - binary_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1195 - binary_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1187 - binary_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1179 - binary_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1171 - binary_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1164 - binary_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1156 - binary_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1149 - binary_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1141 - binary_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1134 - binary_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1127 - binary_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1120 - binary_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1113 - binary_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1106 - binary_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1099 - binary_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1092 - binary_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1085 - binary_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1078 - binary_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1072 - binary_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1065 - binary_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1059 - binary_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1052 - binary_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1046 - binary_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1040 - binary_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1033 - binary_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1027 - binary_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1021 - binary_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1015 - binary_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1009 - binary_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1003 - binary_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0997 - binary_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0991 - binary_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0985 - binary_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0980 - binary_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0974 - binary_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0968 - binary_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0963 - binary_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0957 - binary_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0952 - binary_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0947 - binary_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0941 - binary_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0936 - binary_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0931 - binary_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0925 - binary_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0920 - binary_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0915 - binary_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0910 - binary_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0905 - binary_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0900 - binary_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0895 - binary_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0890 - binary_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0885 - binary_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0881 - binary_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0876 - binary_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0871 - binary_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0867 - binary_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0862 - binary_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0857 - binary_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0853 - binary_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0848 - binary_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0844 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256325385d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02de92ee-b011-4e44-8329-447702a1f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03393155],\n",
       "       [0.07476249],\n",
       "       [0.15675426],\n",
       "       [0.88761616],\n",
       "       [0.9360252 ],\n",
       "       [0.96498555]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-2, -1.5, -1, 1.25, 1.62, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54432144-fa2c-40cb-aa32-afb70c742b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-1000, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "685be4c7-f037-4964-8cc3-00129d2b00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-1.0161469]], dtype=float32)>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f9f9e44-0b16-41ee-a926-8600dc37a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.0161469]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51072713-2937-406d-a342-70a450c90967",
   "metadata": {},
   "source": [
    "# 다중입력 로지스틱회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb59160a-0a80-4840-be33-7d722be4b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 2, units = 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c14c5553-1b4d-45e3-a502-63e6bb3527da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([(0, 0), (0, 1), (1, 0), (1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bbde0fb-9fc4-4dc5-8bf5-1c7327eefee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb423fcb-6fba-41e1-9661-13ee457b15f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25633d049d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=5000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7417d817-4973-4591-afdd-00bd081c4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03642527],\n",
       "       [0.23690067],\n",
       "       [0.20178041],\n",
       "       [0.674901  ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ad94e57-592b-4847-9ab8-7a9f035a8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3 (12.00 Byte)\n",
      "Trainable params: 3 (12.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea69c65f-5b3c-47c8-912b-c5ac6a678cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy=\n",
       " array([[1.9001836],\n",
       "        [2.10564  ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([-3.2753873], dtype=float32)>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a041b66-1648-4042-acfa-dffefcc2c49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.9001836],\n",
       "        [2.10564  ]], dtype=float32),\n",
       " array([-3.2753873], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d5e1e-6c70-4abb-9aba-aba0197019b2",
   "metadata": {},
   "source": [
    "# 십중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c86d3d-116d-4b76-8e0b-5c2998c1901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "036b14b6-047f-4a04-95c5-fb47e1fb1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fee9ee44-78d6-40aa-9c60-18203ec75115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41b7055f-daaf-414a-978a-95b3a4274a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba505d9-19de-4e63-924a-387c331fd039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d5e5daf-8c55-46ce-a772-b0648d172fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0  30  94 170 253 253 225 253 195   0   0 \n",
      "  0   0   0   0 219 253 253 198 247   0   0   0   0   0 \n",
      "  0   0   0   0   0   1 253   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0 190  70   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0 240 253  25   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  93 253   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  46 183 253   2   0   0   0 \n",
      "  0   0   0   0   0  24 221 253 253  78   0   0   0   0 \n",
      "  0   0   0  18 219 253 253  80   0   0   0   0   0   0 \n",
      "  0   0 136 253 212 132   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 28, 2):\n",
    "    for j in range(0, 28, 2):\n",
    "        print(\"%3d\"% X_train[0][i][j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3bcb223-25fe-47c1-8ab3-e2c7bb17f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2133299a-5ae5-4262-a4b1-521484914916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.12 0.37 0.67 0.99 0.99 0.88 0.99 0.76 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.86 0.99 0.99 0.78 0.97 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.99 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.75 0.27 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.94 0.99 0.10 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.36 0.99 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.18 0.72 0.99 0.01 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.09 0.87 0.99 0.99 0.31 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.07 0.86 0.99 0.99 0.31 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.53 0.99 0.83 0.52 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 28, 2):\n",
    "    for j in range(0, 28, 2):\n",
    "        print(\"%.2f\"% X_train[0][i][j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdc17ba4-7909-4634-9a91-ef0bd29428a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b50756dc-1f1a-4c24-a09b-356a5b24756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "X_train=X_train.reshape(60000, input_dim)\n",
    "X_test=X_test.reshape(10000, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be4f8ffe-a26a-4a1e-8d6e-96f59a6c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8a4ff4e-b07a-4305-8983-5af261109589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11d9c4b2-6ad3-49dd-b6b4-97d694634010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim= input_dim, units = 10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3704934-ec47-48fb-94b8-7dd79c0dce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256342273d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss= 'categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(X_train, y_train, batch_size=2048, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "809daaa7-c8dd-49a1-957f-299a019dd548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.421480655670166, 0.8906000256538391]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c33a1f-5e86-4c86-82bc-b51406572a51",
   "metadata": {},
   "source": [
    "# 뉴럴 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a511f47f-bc37-4b4d-8f81-d91ea89a17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e648f4d-cc87-4955-9466-7c95419459fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0, 1),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a99dadaf-1811-41cf-84f8-21961e47edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f73f3da5-e2c8-4c6b-8d99-f20f13aa6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "             ModelCheckpoint(filepath = 'best_model.h5', monitor='val_accuracy', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8706ad2-e9d3-430d-a5aa-b797b0c5dad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.6536 - accuracy: 0.8183 - val_loss: 0.2205 - val_accuracy: 0.9378\n",
      "Epoch 2/300\n",
      "26/54 [=============>................] - ETA: 0s - loss: 0.2498 - accuracy: 0.9265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbong\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 8ms/step - loss: 0.2317 - accuracy: 0.9327 - val_loss: 0.1521 - val_accuracy: 0.9578\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9514 - val_loss: 0.1226 - val_accuracy: 0.9672\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.9636 - val_loss: 0.1117 - val_accuracy: 0.9697\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1030 - accuracy: 0.9707 - val_loss: 0.0934 - val_accuracy: 0.9718\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9756 - val_loss: 0.0893 - val_accuracy: 0.9735\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9795 - val_loss: 0.0803 - val_accuracy: 0.9755\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.0580 - accuracy: 0.9834 - val_loss: 0.0798 - val_accuracy: 0.9763\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9856 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9875 - val_loss: 0.0736 - val_accuracy: 0.9788\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9905 - val_loss: 0.0720 - val_accuracy: 0.9798\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9808\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0692 - val_accuracy: 0.9810\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0675 - val_accuracy: 0.9815\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.0657 - val_accuracy: 0.9820\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.0711 - val_accuracy: 0.9817\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.0712 - val_accuracy: 0.9808\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.0702 - val_accuracy: 0.9813\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.0677 - val_accuracy: 0.9825\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0708 - val_accuracy: 0.9807\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0716 - val_accuracy: 0.9823\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.0702 - val_accuracy: 0.9828\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.0744 - val_accuracy: 0.9818\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0741 - val_accuracy: 0.9820\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0760 - val_accuracy: 0.9827\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0775 - val_accuracy: 0.9842\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0765 - val_accuracy: 0.9832\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0791 - val_accuracy: 0.9825\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9830\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0815 - val_accuracy: 0.9817\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0798 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x256325b3150>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, batch_size = 1000, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "839cf18d-9978-4eaa-a506-8fff49ca1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0727 - accuracy: 0.9803\n",
      "[0.0727401003241539, 0.9803000092506409]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7be366e9-a751-4c64-b222-7247b3818810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c2eadd8-fbe7-4ad2-9b35-8f174a21ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da02d030-f5b1-4548-b90b-d0e42735c2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f529ff72-a045-422c-a2e2-64bd6b07feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.07058824],\n",
       "        [0.49411765],\n",
       "        [0.53333336],\n",
       "        [0.6862745 ],\n",
       "        [0.10196079],\n",
       "        [0.6509804 ],\n",
       "        [1.        ],\n",
       "        [0.96862745],\n",
       "        [0.49803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.11764706],\n",
       "        [0.14117648],\n",
       "        [0.36862746],\n",
       "        [0.6039216 ],\n",
       "        [0.6666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.88235295],\n",
       "        [0.6745098 ],\n",
       "        [0.99215686],\n",
       "        [0.9490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.19215687],\n",
       "        [0.93333334],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.9843137 ],\n",
       "        [0.3647059 ],\n",
       "        [0.32156864],\n",
       "        [0.32156864],\n",
       "        [0.21960784],\n",
       "        [0.15294118],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.7137255 ],\n",
       "        [0.96862745],\n",
       "        [0.94509804],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.3137255 ],\n",
       "        [0.6117647 ],\n",
       "        [0.41960785],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8039216 ],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.16862746],\n",
       "        [0.6039216 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05490196],\n",
       "        [0.00392157],\n",
       "        [0.6039216 ],\n",
       "        [0.99215686],\n",
       "        [0.3529412 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.54509807],\n",
       "        [0.99215686],\n",
       "        [0.74509805],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04313726],\n",
       "        [0.74509805],\n",
       "        [0.99215686],\n",
       "        [0.27450982],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13725491],\n",
       "        [0.94509804],\n",
       "        [0.88235295],\n",
       "        [0.627451  ],\n",
       "        [0.42352942],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.31764707],\n",
       "        [0.9411765 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.46666667],\n",
       "        [0.09803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1764706 ],\n",
       "        [0.7294118 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.5882353 ],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0627451 ],\n",
       "        [0.3647059 ],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.73333335],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.9764706 ],\n",
       "        [0.99215686],\n",
       "        [0.9764706 ],\n",
       "        [0.2509804 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18039216],\n",
       "        [0.50980395],\n",
       "        [0.7176471 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.8117647 ],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15294118],\n",
       "        [0.5803922 ],\n",
       "        [0.8980392 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.98039216],\n",
       "        [0.7137255 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09411765],\n",
       "        [0.44705883],\n",
       "        [0.8666667 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7882353 ],\n",
       "        [0.30588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09019608],\n",
       "        [0.25882354],\n",
       "        [0.8352941 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7764706 ],\n",
       "        [0.31764707],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.67058825],\n",
       "        [0.85882354],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.7647059 ],\n",
       "        [0.3137255 ],\n",
       "        [0.03529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.6745098 ],\n",
       "        [0.8862745 ],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.52156866],\n",
       "        [0.04313726],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.53333336],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.83137256],\n",
       "        [0.5294118 ],\n",
       "        [0.5176471 ],\n",
       "        [0.0627451 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b29c179-1c07-4530-8c03-3ef33a74b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94bbb0eb-d199-4237-9af1-b9b6271b6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a556fa0-064f-4bc1-8f0b-1eb75dcc217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "             ModelCheckpoint(filepath = 'best_model_cnn.h5', monitor='val_accuracy', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c784d57-0be0-422a-9d71-973a7fd29e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "108/108 [==============================] - 18s 160ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 2/300\n",
      "108/108 [==============================] - 19s 180ms/step - loss: 0.0560 - accuracy: 0.9834 - val_loss: 0.0502 - val_accuracy: 0.9868\n",
      "Epoch 3/300\n",
      "108/108 [==============================] - 20s 183ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0452 - val_accuracy: 0.9878\n",
      "Epoch 4/300\n",
      "108/108 [==============================] - 20s 182ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0369 - val_accuracy: 0.9887\n",
      "Epoch 5/300\n",
      "108/108 [==============================] - 18s 170ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.0407 - val_accuracy: 0.9883\n",
      "Epoch 6/300\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0375 - val_accuracy: 0.9898\n",
      "Epoch 7/300\n",
      "108/108 [==============================] - 17s 160ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0377 - val_accuracy: 0.9893\n",
      "Epoch 8/300\n",
      "108/108 [==============================] - 17s 158ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0324 - val_accuracy: 0.9902\n",
      "Epoch 9/300\n",
      "108/108 [==============================] - 18s 163ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0354 - val_accuracy: 0.9915\n",
      "Epoch 10/300\n",
      "108/108 [==============================] - 20s 181ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0346 - val_accuracy: 0.9917\n",
      "Epoch 11/300\n",
      "108/108 [==============================] - 19s 174ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0342 - val_accuracy: 0.9903\n",
      "Epoch 12/300\n",
      "108/108 [==============================] - 19s 179ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0364 - val_accuracy: 0.9893\n",
      "Epoch 13/300\n",
      "108/108 [==============================] - 20s 184ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9917\n",
      "Epoch 14/300\n",
      "108/108 [==============================] - 19s 171ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0387 - val_accuracy: 0.9897\n",
      "Epoch 15/300\n",
      "108/108 [==============================] - 20s 189ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0338 - val_accuracy: 0.9918\n",
      "Epoch 16/300\n",
      "108/108 [==============================] - 18s 168ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0410 - val_accuracy: 0.9910\n",
      "Epoch 17/300\n",
      "108/108 [==============================] - 17s 161ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 18/300\n",
      "108/108 [==============================] - 19s 174ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0387 - val_accuracy: 0.9925\n",
      "Epoch 19/300\n",
      "108/108 [==============================] - 18s 164ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 20/300\n",
      "108/108 [==============================] - 20s 186ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0395 - val_accuracy: 0.9910\n",
      "Epoch 21/300\n",
      "108/108 [==============================] - 18s 169ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0501 - val_accuracy: 0.9902\n",
      "Epoch 22/300\n",
      "108/108 [==============================] - 19s 173ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0382 - val_accuracy: 0.9935\n",
      "Epoch 23/300\n",
      "108/108 [==============================] - 17s 160ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0427 - val_accuracy: 0.9913\n",
      "Epoch 24/300\n",
      "108/108 [==============================] - 17s 157ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0428 - val_accuracy: 0.9925\n",
      "Epoch 25/300\n",
      "108/108 [==============================] - 18s 170ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0413 - val_accuracy: 0.9912\n",
      "Epoch 26/300\n",
      "108/108 [==============================] - 19s 180ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0447 - val_accuracy: 0.9923\n",
      "Epoch 27/300\n",
      "108/108 [==============================] - 16s 151ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2564ac4d650>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, epochs=300, verbose=1, validation_split=0.1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5237fa4-b3ac-4a99-9767-3b9981888607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9924\n",
      "[0.02922121062874794, 0.9923999905586243]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
